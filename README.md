# ğŸ“Š AnÃ¡lise de EvasÃ£o de Clientes (Churn Prediction)

Este projeto tem como objetivo identificar os principais fatores que influenciam a evasÃ£o de clientes em uma empresa de telecomunicaÃ§Ãµes, utilizando tÃ©cnicas de aprendizado de mÃ¡quina para construir modelos preditivos confiÃ¡veis. A proposta vai alÃ©m da previsÃ£o: buscamos entender o "porquÃª" da saÃ­da e propor estratÃ©gias prÃ¡ticas de retenÃ§Ã£o.

---

## ğŸ’¡ Objetivos

- Analisar o perfil dos clientes e identificar padrÃµes de evasÃ£o.
- Aplicar tÃ©cnicas de Machine Learning para prever o churn.
- Comparar o desempenho entre modelos com e sem normalizaÃ§Ã£o.
- Utilizar balanceamento de classes (SMOTE) para melhorar a equidade dos modelos.
- Gerar insights claros e aplicÃ¡veis para estratÃ©gias de retenÃ§Ã£o.

---

## ğŸ§  Modelos Utilizados

Foram testados dois modelos principais:

### 1. **RegressÃ£o LogÃ­stica com SMOTE**
- Requer normalizaÃ§Ã£o dos dados.
- Bom para interpretar a influÃªncia de cada variÃ¡vel (coeficientes).
- Destaque para variÃ¡veis como `Encargos_Mensais`, `Encargos_Totais` e `Tempo_Servico`.

### 2. **Random Forest com SMOTE**
- NÃ£o exige normalizaÃ§Ã£o.
- Indicado para captar relaÃ§Ãµes complexas entre variÃ¡veis.
- Destaque para `Tempo_Servico`, `Encargos_Totais`, e `Contrato_Conta`.

---

## ğŸ” Principais Insights

### ğŸ”¥ Fatores que aumentam a evasÃ£o:
- Altos **encargos mensais** e **totais**.
- Clientes com **contrato mensal**.
- UsuÃ¡rios de **internet por fibra Ã³ptica**, que apesar de mais veloz, podem ter maiores custos e expectativas.
- Baixo tempo de serviÃ§o com a empresa.

### â„ï¸ Fatores que reduzem a evasÃ£o:
- Clientes **antigos**, com maior tempo de vÃ­nculo.
- UsuÃ¡rios com **contrato bienal**.
- Clientes que **possuem dependentes ou parceiro** no cadastro â€” sinal de envolvimento mais profundo com o serviÃ§o.

---

## ğŸ› ï¸ TÃ©cnicas Aplicadas

- **PrÃ©-processamento** de dados (encoding, normalizaÃ§Ã£o).
- **Balanceamento de classes com SMOTE**.
- **GridSearchCV** para ajuste de hiperparÃ¢metros.
- **AvaliaÃ§Ã£o com mÃ©tricas clÃ¡ssicas**: AcurÃ¡cia, PrecisÃ£o, Recall, F1-score, e Matriz de ConfusÃ£o.
- **AnÃ¡lise interpretativa dos coeficientes e importÃ¢ncias das variÃ¡veis**.

---

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

| Modelo                       | AcurÃ¡cia | PrecisÃ£o | Recall | F1-score |
|-----------------------------|----------|----------|--------|----------|
| RegressÃ£o LogÃ­stica (SMOTE) | 0.7611   | 0.5287   | 0.6578 | 0.5862   |
| Random Forest (SMOTE)       | 0.7652   | 0.5375   | 0.6257 | 0.5783   |

Ambos os modelos apresentaram desempenho semelhante. A regressÃ£o logÃ­stica se destacou no recall, enquanto a random forest apresentou maior estabilidade geral.

---

## ğŸ¯ ConclusÃ£o

A anÃ¡lise demonstrou que a evasÃ£o nÃ£o acontece ao acaso â€” ela responde a padrÃµes claros de comportamento, relacionamento e percepÃ§Ã£o de valor. Modelos preditivos, quando bem interpretados, tornam-se aliados estratÃ©gicos na construÃ§Ã£o de aÃ§Ãµes mais humanas, personalizadas e eficazes.

> *â€œMais do que prever a saÃ­da, este projeto busca compreender o silÃªncio antes da despedida â€” e transformÃ¡-lo em oportunidade de reconexÃ£o.â€*

---

## ğŸ’» Como Usar

- Clone o repositÃ³rio
- Abra o notebook .ipynb no Jupyter ou Google Colab
- Execute as cÃ©lulas para seguir a anÃ¡lise passo a passo

## ğŸ§¾ Requisitos

- Python 3.x
- pandas, numpy, matplotlib, seaborn
- scikit-learn, imblearn

---

## ğŸ§  PrÃ³ximos Passos

- Testar novos modelos (XGBoost, LightGBM).
- Explorar variÃ¡veis temporais e de engajamento mais profundo.
- Integrar os resultados a uma dashboard interativa.

---

## âœï¸ Autoria

**Carolini Rufino**  
Estudante de Data Science | SecretÃ¡ria | Bacharel em AdministraÃ§Ã£o de Empresas

ğŸ“§ carolinirufino@gmail.com

ğŸ”— [LinkedIn](https://www.linkedin.com/in/carolinirufino)

---
